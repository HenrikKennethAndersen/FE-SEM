---
title: |
  | Supplementary materials for: 
  | A closer look at fixed effects regression in structural equation modeling using \texttt{lavaan}
#type: ARTICLE TEMPLATE
author:
  - name: Henrik Kenneth Andersen
    affil: a
    email: henrik.andersen@soziologie.tu-chemnitz.de
affiliation:
  - num: a
    address: |
      Chemnitz University of Technology, Institute of Sociology, Chair for Empirical Social Research, Th√ºringer Weg 9, 09126 Chemnitz, Germany
bibliography: references2.bib
# appendix: appendix.tex
header-includes: |
  \usepackage{hyperref}
  \usepackage[utf8]{inputenc}
  \usepackage{booktabs}
  \usepackage{bm}
  \usepackage{mathtools}
  \usepackage{amssymb}
  \usepackage{amsmath}
  \usepackage{tikz}
  \usetikzlibrary{arrows}
  \usepackage[nofiglist]{endfloat}
  \usepackage{blkarray}
  \usepackage{setspace}
  \usepackage{etoolbox}
  \DeclareMathOperator{\E}{\mathbb{E}}
  \DeclareMathOperator{\Var}{\mathrm{Var}}
  \DeclareMathOperator{\Cov}{\mathrm{Cov}}
  \DeclareMathOperator*{\argmax}{arg\,max}
  \DeclareMathOperator*{\argmin}{arg\,min}
  \mathtoolsset{showonlyrefs}
  \BeforeBeginEnvironment{equation}{\begin{singlespace}\vspace*{-\baselineskip}}
  \AfterEndEnvironment{equation}{\end{singlespace}\noindent\ignorespaces}
  \BeforeBeginEnvironment{align}{\begin{singlespace}\vspace*{-\baselineskip}}
  \AfterEndEnvironment{align}{\end{singlespace}\noindent\ignorespaces}
  \def\tightlist{}
  \pagenumbering{gobble}
output: rticles::tf_article
---

```{r setup, include=FALSE}
# Knitr options 
knitr::opts_chunk$set(echo = TRUE)

# Packages (some are repeated below, add them here as well just to be sure)
library(formatR)
library(knitr)
library(lavaan)

# Script hooks for chunk outputs
source("../scripthooks.R")
```

```{r echo=FALSE}
df <- readRDS("../longData.Rda")
dfw <- readRDS("../wideData.Rda")

n <- readRDS("../n.Rda")
waves <- readRDS("../waves.Rda")

fe_sem <- readRDS("../fe_sem.Rda")
fe_sem.fit <- readRDS("../fe_sem.fit.Rda")
```

---

The following goes into some more detail on the comparison of traditional FE and FE-SEM models and discusses several opportunities to extend the basic FE model outlined in the main article, and provides concrete guidance on the implementation in `lavaan`. First, I verify that the FE-SEM model does, in fact, return essentially identical results compared to the more traditional methods. Then, I go over a number of possibilities to relax assumptions associated with the traditional FE model. Then, I discuss the issue of measurement error and show how we can use latent variables to deal with it and properly estimate the coefficients of interest. Then, I show a type of hybrid FE/RE model that allows us to control for time-invariant unobserved heterogeneity while including time-invariant predictors in the model.   

# Model notation 

The following is an outline of matrix notation for those that prefer it to the path diagrams and model syntax. There are a number of different model notations (see, for example @Bollen1989 for an overview), but the one that will serve us best is one that was proposed by @Graff1979:
\begin{align}
\bm{y}^{*} & = \bm{\Lambda_{y}}^{*} \bm{\eta}^{*}, \\
\bm{\eta}^{*} & = \bm{B}\bm{\eta}^{*} + \bm{\zeta}^{*}, 
\end{align}
where $\bm{\eta}^{*} = (\bm{y}, \bm{x}, \bm{\eta}, \bm{\xi})^{\intercal}$, $\bm{\zeta}^{*} = (\bm{\varepsilon}, \bm{\delta}, \bm{\zeta}, \bm{\xi})^{\intercal}$, $\bm{y}^{*} = (\bm{y}, \bm{x})^{\intercal}$. $\bm{y}$ is a vector of observed dependent variables and $\bm{x}$ is a vector of observed independent variables. $\bm{\eta}$ is a vector of the latent dependent variables and $\bm{\xi}$ is a vector of latent independent variables. $\bm{\varepsilon}$ and $\bm{\delta}$ are vectors of the errors of the observed dependent and independent variables, respectively, and $\bm{\zeta}$ is a vector of the errors, or disturbances, of the latent variables. Notice the $^{*}$ symbol is just meant to differentiate the vectors with them from those without them. That means, $\bm{\eta}^{*}$ is a vector that holds the observed and latent variables, both dependent (in SEM they are referred to as 'endogenous') and independent (i.e., 'exogeneous')^[For our purposes, the terms endogenous and dependent, on the one hand, and exogenous and independent, on the other, can be used interchangeably.], $\bm{\zeta}^{*}$ holds the errors for the observed variables and the disturbances of the latent variables. $\bm{y}^{*}$ holds just the observed variables, both dependent and independent, and $\bm{\Lambda_{y}}^{*}$ is a matrix of ones and zeros that selects the observed variables from $\bm{\eta}^{*}$. Lastly, $\bm{B}$ is a matrix that holds the regression coefficients.^[If we say that $p$ and $q$ stand for the number of observed dependent and independent variables, respectively, and $m$ and $n$ stand for the number of latent dependent and independent variables, respectively, then $\bm{\eta}^{*}$ and $\bm{\zeta}^{*}$ are $p + q + m + n$, $\bm{y}^{*}$ is $p + q$, $\bm{\Lambda_{y}}^{*}$ is $(p + q) \times (p + q + m + n)$ and $\bm{B}$ is $(p + q + m + n) \times (p + q + m + n)$ [@Bollen1989].]

This notation may be confusing at first, but it has advantages. First, it allows us the flexibility we need for the models. For example, it allows observed $\bm{x}$ to directly influence observed $\bm{y}$ (more common notation assumes that substantive effects occur only between latent variables, observed ones are only used as indicators, see for example @Bollen1989, @Kline2016). It also allows $\bm{\xi}$, i.e., any latent exogenous variables, to influence $\bm{y}$ directly. These two scenarios cover the traditional FE model with observed variables, and one in which latent variables are used to account for measurement error in the independent variables. It is also consistent with the notation used for these models in `lavaan`. In fact, `lavaan` switches automatically between matrix notations depending on the specified model. That means the matrix representation of the model one sees if they type in `lavInspect(model, what = "est")` after specifying their model in `lavaan` will match up with the notation used here.^[In `Mplus`, the model matrices can be requested by including `OUTPUT: TECH1` in the input file.] It does have a potential disadvantage however. Besides being less intuitive than the typical $\bm{\eta} = \bm{B}\bm{\eta} + \bm{\Gamma}\bm{\xi} + \bm{\zeta}$ notation, it means that by including the observed covariates in the stacked long vector $\bm{y}^{*}$, they are treated as another response variable with variances and covariances to be estimated by the model (instead of just using the sample statistics). This means that the assumption of multivariate normality (otherwise just imposed on the dependent variables) also applies to the independent ones [@Skrondal2004, p. 75]. This can be problematic for noncontinuous independent variables like sex, nationality dummies, marriage status (married/unmarried), etc. See @Skrondal2004 for more on this topic.  

Let us, however, make things more concrete and take a look at a simple, three-wave version of the typical FE-SEM using this notation (shown graphically in Figure \ref{fig:fesem}). For that, we have the following matrix notation (with labels on the outside of the matrices):
\begin{align}
\begin{split}
\bm{y}^{*} & = \bm{\Lambda_{y}}^{*}\bm{\eta}^{*} \\
\begin{pmatrix}
y_{1} \\
y_{2} \\
y_{3} \\
x_{1} \\
x_{2} \\
x_{3}
\end{pmatrix} & = 
\begin{blockarray}{cccccccc}
 & y_{1} & y_{2} & y_{3} & x_{1} & x_{2} & x_{3} & \alpha \\
 \begin{block}{c(ccccccc)}
 y_{1} & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\
 y_{2} & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\
 y_{3} & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\ 
 x_{1} & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\
 x_{2} & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\
 x_{3} & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\
 \end{block}
\end{blockarray}
\begin{pmatrix}
y_{1} \\
y_{2} \\
y_{3} \\
x_{1} \\
x_{2} \\
x_{3} \\
\alpha
\end{pmatrix},
\end{split} \label{eq:y}
\end{align}
\begin{align}
\begin{split}
\bm{\eta}^{*} & = \bm{B}\bm{\eta}^{*} + \bm{\zeta}^{*} \\
\begin{pmatrix}
y_{1} \\
y_{2} \\
y_{3} \\
x_{1} \\
x_{2} \\
x_{3} \\
\alpha
\end{pmatrix} & = 
\begin{blockarray}{cccccccc}
 & y_{1} & y_{2} & y_{3} & x_{1} & x_{2} & x_{3} & \alpha \\
 \begin{block}{c(ccccccc)}
 y_{1}  & 0 & 0 & 0 & \beta & 0 & 0 & 1 \\
 y_{2}  & 0 & 0 & 0 & 0 & \beta & 0 & 1\\
 y_{3}  & 0 & 0 & 0 & 0 & 0 & \beta & 1 \\ 
 x_{1}  & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
 x_{2}  & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
 x_{3}  & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
 \alpha & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
 \end{block}
\end{blockarray}
\begin{pmatrix}
y_{1} \\
y_{2} \\
y_{3} \\
x_{1} \\
x_{2} \\
x_{3} \\
\alpha
\end{pmatrix} + 
\begin{pmatrix}
\varepsilon_{1} \\
\varepsilon_{2} \\
\varepsilon_{3} \\
x_{1} = \delta_{1} \\
x_{2} = \delta_{2} \\
x_{3} = \delta_{3} \\
\alpha = \xi \\
\end{pmatrix}. 
\end{split} \label{eq:eta}
\end{align} 
Notice in $\bm{\zeta}^{*}$, for the independent variables we could either write, for example $x_{t}$ or $\delta_{t}$. As mentioned above, this is due to the model notation treating the independent variables like dependent variables with variances/covariances to be estimated. For the sake of simplicity, we will ignore this subtlety and refer to the observed variable from now on, keeping in mind that if the multivariate normality assumption holds, the estimated statistics will likely be sufficiently close to the sample ones for it to not make much of a difference. 

Admittedly, Equations \eqref{eq:y} and \eqref{eq:eta} may not look like much yet. We can remedy this by first putting the equation for $\bm{\eta}^{*}$ in reduced form, i.e., by getting rid of the dependent variable on the r.h.s.: 
\begin{align}
\bm{\eta}^{*} & = \bm{B}\bm{\eta}^{*} + \bm{\zeta}^{*} \\
\bm{\eta}^{*} - \bm{B}\bm{\eta}^{*} & = \bm{\zeta}^{*} \\
(\bm{I} - \bm{B})\bm{\eta}^{*} & = \bm{\zeta}^{*} \\
\bm{\eta}^{*} & = (\bm{I} - \bm{B})^{-1}\bm{\zeta}^{*},
\end{align}
where $\bm{I}$ is the identity matrix. By substituting this back into the equation for the observed variables we get $\bm{y}^{*} = \bm{\Lambda_{y}}^{*}[(\bm{I} - \bm{B})^{-1}\bm{\zeta}^{*}]$, which works out to:
\begin{align}
\begin{pmatrix} 
y_{1} \\
y_{2} \\
y_{3} \\
x_{1} \\
x_{2} \\
x_{3} \\
\end{pmatrix} & = 
\begin{pmatrix}
\alpha + \beta x_{1} + \varepsilon_{1} \\
\alpha + \beta x_{2} + \varepsilon_{2} \\
\alpha + \beta x_{3} + \varepsilon_{3} \\
x_{1} \\
x_{2} \\
x_{3}
\end{pmatrix},
\end{align}
which is of course exactly what we should expect given Equation \eqref{eq:fe}^[We can use the `sympy` package in `python` to verify and show the steps for this and other examples, see the [supplementary materials](https://github.com/henrik-andersen/FE-SEM/blob/master/sympy-doublecheck-matrixnotation.py) for the code.]. 

## Assumptions 

What essentially differentiates an FE from an RE model is our assumption concerning the relationship between the unobserved individual effects and the model covariates [@Bollen2010]. The FE model assumes that $\E[\alpha x_{t}] \ne 0$. As such, if we fail to control for the correlation of the covariate and the time-invariant part of the error, then the coefficient of interest, here $\beta$, will be biased. Our assumption regarding whether the individual effects are correlated with the model covariates occurs in $\E[\bm{\zeta}^{*}\bm{\zeta}^{* \intercal}] = \bm{\Psi}$, the covariance matrix of the errors
\begin{align}
\bm{y}^{*}\bm{y}^{* \intercal} & = \E[(\bm{\Lambda_{y}}^{*}(\bm{I} - \bm{B})^{-1}\bm{\zeta}^{*})(\bm{\Lambda_{y}}^{*}(\bm{I} - \bm{B})^{-1}\bm{\zeta}^{*})^{\intercal}] \\
 & = \E[(\bm{\Lambda_{y}}^{*}(\bm{I} - \bm{B})^{-1}\bm{\zeta}^{*})(\bm{\zeta}^{* \intercal}(\bm{I} - \bm{B})^{-1 \intercal}\bm{\Lambda_{y}}^{* \intercal})] \\
 & = \bm{\Lambda_{y}}^{*}(\bm{I} - \bm{B})^{-1} \E[\bm{\zeta}^{*}\bm{\zeta}^{* \intercal}] (\bm{I} - \bm{B})^{-1 \intercal}\bm{\Lambda_{y}}^{* \intercal} \\
 & = \bm{\Lambda_{y}}^{*}(\bm{I} - \bm{B})^{-1} \bm{\Psi} (\bm{I} - \bm{B})^{-1 \intercal}\bm{\Lambda_{y}}^{* \intercal}.
\end{align}
In the case of an FE model, $\bm{\Psi}$ will reflect our belief that the individual effects are correlated with the model covariates, here again for demonstration the three-wave model:
\begin{align}
\bm{\Psi} & = \E
\begin{blockarray}{cccccccc}
 & \varepsilon_{1} & \varepsilon_{2} & \varepsilon_{3} & x_{1} & x_{2} & x_{3} & \alpha \\
 \begin{block}{c(ccccccc)}
 \varepsilon_{1} & \varepsilon_{1}^{2} &                     &                     &              &              &              & \\
 \varepsilon_{2} & 0                   & \varepsilon_{2}^{2} &                     &              &              &              & \\
 \varepsilon_{3} & 0                   & 0                   & \varepsilon_{3}^{2} &              &              &              & \\
 x_{1}           & 0                   & 0                   & 0                   & x_{1}^{2}    &              &              & \\
 x_{2}           & 0                   & 0                   & 0                   & x_{2}x_{1}   & x_{2}^{2}    &              & \\
 x_{3}           & 0                   & 0                   & 0                   & x_{3}x_{1}   & x_{3}x_{2}   & x_{3}^{2}    & \\
 \alpha          & 0                   & 0                   & 0                   & \alpha x_{1} & \alpha x_{2} & \alpha x_{3} & \alpha^{2} \\
 \end{block}
\end{blockarray}.
\end{align}
Knowing this, we can work out the equation for the coefficient of interest, $\beta$. For the sake of simplicity, assume here and throughout mean-centered variables: 
\begin{align}
\Cov(y_{t},x_{t}) & = \E[y_{t}x_{t}] \\
 & = \E[(\alpha + \beta x_{t} + \varepsilon_{t})x_{t}] \\
 & = \E[\alpha x_{t} + \beta x_{t}^{2} + \varepsilon_{t}x_{t}] \\
 & = \Cov(\alpha, x_{t}) + \beta \Var(x_{t}) \\
\hat{\beta}_{FE-SEM} & = \frac{\Cov(y_{t},x_{t}) - \Cov(\alpha, x_{t})}{\Var(x_{t})}. 
\end{align}
This should make intuitive sense. From the observed covariance between the dependent and the independent variable, we are partialling out the part that is due to the covariance between the independent variable and the individual effects per unit, and then dividing by the variance of the independent variable, as usual. For the RE model, we assume $\E[\alpha x_{t}] = 0$ and the equation reduces to $\hat{\beta}_{RE-SEM} = \Cov(y_{t},x_{t})/\Var(x_{t})$. The rest of the model-implied covariance matrix results from $\bm{y}^{*}\bm{y}^{* \intercal}$.

# A comparison with non-SEM methods

Just to be sure that the FE-SEM results do, in fact, line up with the more traditional methods outlined in Section 2 of the main article, we can use the long-format data (see [the supplementary materials at](https://github.com/henrik-andersen/FE-SEM)) to run the typical FE model using the `plm` package [@R-plm_a]. By default, the `plm` function assumes the dataframe is structured so that the first two columns correspond to the individual and time indices, see the [documentation](https://cran.r-project.org/web/packages/plm/plm.pdf) or @R-plm_a. 

```{r message=FALSE, warning=FALSE, error=FALSE}
library(plm)

# Run the FE model in plm 
fe1 <- plm(y ~ x, 
           effect = "individual", model = "within", 
           data = df)
summary(fe1)
```

From this, we see that the results are, indeed, essentially identical, with $\hat{\beta}_{FE-SEM} =`r round(lavInspect(fe_sem.fit, "list")[6, 14], 3)` \ (`r round(lavInspect(fe_sem.fit, "list")[6, 15], 3)`)$ and $\hat{\beta}_{FE} = `r round(summary(fe1)$coefficients[1, 1], 3)` \ (`r round(summary(fe1)$coefficients[1, 2], 3)`)$.

Other methods of estimating FE models work in the random or mixed effects model framework. For example, we can include the cluster means per individual of the time-varying independent variables, here $x$, in the equation to achieve within estimates [@Mundlak1978; @Chamberlain1980; @Wooldridge2002]. 

```{r}
# Generate the cluster means for x per id 
clusterMeanx <- aggregate(df$x, by = list(df$id), FUN = mean)
# Rename the columns 
names(clusterMeanx) <- c("id", "xbar")

# Add the cluster means back into df  
df <- merge(df, clusterMeanx, by = "id")
```

Here using the `plm` function in the `random` setup: 

```{r}
fe2 <- plm(y ~ x + xbar, 
           effect = "individual", model = "random",
           data = df)
summary(fe2)
```

And here using the `lmer` function of the `lme4` package [@Bates2015] to estimate a mixed model: 

```{r message=FALSE, error=FALSE, warning=FALSE}
library(lme4)

# Run the mixed model in lmer with the cluster means for x 
mixed1 <- lmer(y ~ x + xbar + (1 | id), data = df)
summary(mixed1)
```

In both cases, the models return the same estimates as the FE and FE-SEM models. Also, in both the `random` setup using the `plm` function, and the mixed model using the `lmer` function, we get estimates of the variance components, $\hat{\sigma}^{2}_{\alpha}$ and $\hat{\sigma}^{2}_{\varepsilon}$: 

```{r}
# Print the variance components for the plm model  
print(ercomp(fe2), 
      digits = 3)

# Print the variance components for the lmer model 
print(VarCorr(mixed1), 
      comp = c("Variance", "Std.Dev"), 
      digits = 3)
```

From this we see both models report the same estimated variance components, $\hat{\sigma}^{2}_{\alpha} = `r round(ercomp(fe2)[[1]][2], 3)`$ and $\hat{\sigma}^{2}_{\varepsilon} = `r round(ercomp(fe2)[[1]][1], 3)`$, telling us that about `r round(ercomp(fe2)[[1]][2]/(ercomp(fe2)[[1]][1] + ercomp(fe2)[[1]][2]), 3)*100`% of the residual variance is due to the differences between individuals (shown in the `share` column of the `ercomp()` output). This is what is referred to as the intraclass correlation coefficient, or ICC [@Hox2010]. 

# Extensions {#exten}

## Relaxing assumptions meant to mimic traditional FE models {#relax}

There are a number of implicit assumptions attached to the typical FE model that can be relaxed in SEM. Some of these assumptions have been discussed already, and a fairly comprehenisve list of assumptions can be found in @Bollen2010. Here, I will go over just a few, concentrating on the implementation in `lavaan` and the opportunity to empirically test whether the adjustments are justified or not. 

The assumptions we will discuss here pertain to the time-invariance of the effects of both the latent individual effects and the observed covariates, as well as a time-invariant error variance. We can also empirically test the correlation between the individual effects and the covariates to see whether a RE model is preferable to the FE model. 

For example, we can rewrite the original FE equation as
\begin{align}
y_{it} & = \beta_{t}x_{it} + \lambda_{t}\alpha_{i} + \varepsilon_{it}
\end{align}
where $\beta$ becomes $\beta_{t}$ and the implicit regression weight of one turns to $\lambda_{t}$ to highlight the fact that the effect of $x$ as well as $\alpha$ on $y$ may vary over time. We can furthermore easily relax the assumption of time-constant error variance, i.e., $\sigma^{2}_{\varepsilon_{t}}$. As noted in the [main article](https://github.com/henrik-andersen/FE-SEM/blob/master/article.pdf), the assumption regarding $\E[\alpha x_{t}]$ in $\bm{\Psi}$ determines whether we have an FE or RE model. We can set these to zero and test whether the RE model would be preferable to the FE model. In general, if the individual effects are truly uncorrelated with the model covariates, it is advisable to switch to an RE model since because it uses up less degrees of freedom, it will have smaller standard errors [@Bollen2010]. 

In the following `lavaan` code, we simply remove the factor loadings of one for the latent individual effect variable which allows them to be estimated freely at each timepoint. For the effect of the covariate, we can either delete the constraints `b` in `yt ~ b*xt` or give each regression a different label, e.g., `b1`, `b2`, `b3`, etc. Similarly, to allow the error variance to vary over time, we turn the constraints `e` into simple labels, i.e., `e1`, `e2`, `e3`, etc., or again just delete them. In fact, regarding the error variances, they will be estimated necessarily, and do not need to be explicitly mentioned in the model syntax at all. Finally, to move from an FE to an RE model, we could simply constrain the correlations between the individual effects and the covariates to zero, i.e., `a ~~ 0*x1 + 0*x2 + 0*x3 + 0*x4 + 0*x5`. 

```{r eval=FALSE}
fe_sem_fullyrelaxed <- '
# Define individual effects variable 
a =~ y1 + y2 + y3 + y4 + y5
# Regressions, constrain coefficient to be equal over time
y1 ~ b1*x1
y2 ~ b2*x2 
y3 ~ b3*x3
y4 ~ b4*x4
y5 ~ b5*x5
# Allow unrestricted correlation between eta and covariates
a ~~ x1 + x2 + x3 + x4 + x5
# Alternatively: constrain all to 0 for RE model, or
# just individual correlations
# a ~~ 0*x1 + 0*x2 + 0*x3 + 0*x4 + 0*x5
x1 ~~ x2 + x3 + x4 + x5
x2 ~~ x3 + x4 + x5
x3 ~~ x4 + x5
x4 ~~ x5
# Constrain residual variances to be equal over time
y1 ~~ e1*y1
y2 ~~ e2*y2
y3 ~~ e3*y3
y4 ~~ e4*y4
y5 ~~ e5*y5
'
fe_sem_fullyrelaxed.fit <- sem( model = fe_sem_fullyrelaxed, 
                                data = dfw, 
                                estimator = "ML")
```

```{r echo=FALSE, warning=FALSE, message=FALSE, error=FALSE}
re_sem <- '
# Define individual effects variable 
a =~ 1*y1 + 1*y2 + 1*y3 + 1*y4 + 1*y5
# Regressions, constrain coefficient to be equal over time
y1 ~ b*x1
y2 ~ b*x2 
y3 ~ b*x3
y4 ~ b*x4
y5 ~ b*x5
# Allow unrestricted correlation between eta and covariates
a ~~ 0*x1 + 0*x2 + 0*x3 + 0*x4 + 0*x5
x1 ~~ x2 + x3 + x4 + x5
x2 ~~ x3 + x4 + x5
x3 ~~ x4 + x5
x4 ~~ x5
# Constrain residual variances to be equal over time
y1 ~~ e*y1
y2 ~~ e*y2
y3 ~~ e*y3
y4 ~~ e*y4
y5 ~~ e*y5
'
re_sem.fit <- sem( model = re_sem, 
                   data = dfw, 
                   estimator = "ML")
```

As outlined in @Bollen2010, the researcher has the opportunity to test each of the assumptions empirically and decide whether a more parsimonious, i.e., restrictive model is justifiable. For each assumption, a likelihood ratio test can be carried out to determine whether the improvement to model fit resulting from the relaxation of various assumptions is significant or whether the more parsimonious model is preferable after all. 

If we use the original model `fe_sem.fit` (from the [main article](https://github.com/henrik-andersen/FE-SEM/blob/master/article.pdf)) as a starting point, the best strategy for testing these assumptions is to work in a stepwise fashion, relaxing one assumption at a time. We can begin by first constraining the correlation between $\alpha$ and $x_{t}$ to zero (`re_sem`) for an RE model. If turning from an FE to an RE model does not significantly worsen model fit, we can go forward with the rest of the steps with the RE model. If, however, the fit does worsen significantly, it is likely better to stick with the FE model; moving forward then with it to see if a less restrictive FE model is preferable. We can perform a likelihood ratio test in `R` using the `anova()` function:

\small
```{r}
anova( fe_sem.fit, re_sem.fit)
```
\normalsize

The table that is generated shows a comparison of the nested models, in decending order according to degrees of freedom. The RE model does not estimate the correlations between the individual effects and the covariates, so it is more parsimonious and thus listed at the bottom. The `Chisq` column shows the $\chi^{2}$ statistic for both models and the `Chisq diff` column calculates the difference between the two. Obviously, according to the DGP, the correlation between the individual effects and $x_{t}$ is not zero, so fixing these to zero leads to a substantial amount of misfit. The last column puts the $\chi^{2}$ difference in relation to the difference in degrees of freedom and gives a p-value for the probability that the difference is solely due to chance. Here, the change in $\chi^{2}$ is highly significant, so the FE model should be retained. 

After now having established once and for all that FE is our preferred model, we can begin relaxing the rest of the assumptions. I show the following merely as a demonstration of the procedure, we know already from the DGP that the parsimonious model as specified in `fe_sem.fit` is appropriate. We can next allow the error variances (`fe_semb.fit`), the effect of $x$ on $y$ (`fe_semc.fit`) and finally the factor loadings of the individual effects (`fe_semd.fit`) all to vary over time. 

```{r echo=FALSE}
fe_semb <- '
# Define individual effects variable 
a =~ 1*y1 + 1*y2 + 1*y3 + 1*y4 + 1*y5
# Regressions, constrain coefficient to be equal over time
y1 ~ b*x1
y2 ~ b*x2 
y3 ~ b*x3
y4 ~ b*x4
y5 ~ b*x5
# Allow unrestricted correlation between eta and covariates
a ~~ x1 + x2 + x3 + x4 + x5
x1 ~~ x2 + x3 + x4 + x5
x2 ~~ x3 + x4 + x5
x3 ~~ x4 + x5
x4 ~~ x5
# Constrain residual variances to be equal over time
y1 ~~ e1*y1
y2 ~~ e2*y2
y3 ~~ e3*y3
y4 ~~ e4*y4
y5 ~~ e5*y5
'
fe_semb.fit <- sem( model = fe_semb, 
                   data = dfw, 
                   estimator = "ML")

fe_semc <- '
# Define individual effects variable 
a =~ 1*y1 + 1*y2 + 1*y3 + 1*y4 + 1*y5
# Regressions, constrain coefficient to be equal over time
y1 ~ b1*x1
y2 ~ b2*x2 
y3 ~ b3*x3
y4 ~ b4*x4
y5 ~ b5*x5
# Allow unrestricted correlation between eta and covariates
a ~~ x1 + x2 + x3 + x4 + x5
x1 ~~ x2 + x3 + x4 + x5
x2 ~~ x3 + x4 + x5
x3 ~~ x4 + x5
x4 ~~ x5
# Constrain residual variances to be equal over time
y1 ~~ e1*y1
y2 ~~ e2*y2
y3 ~~ e3*y3
y4 ~~ e4*y4
y5 ~~ e5*y5
'
fe_semc.fit <- sem( model = fe_semc, 
                   data = dfw, 
                   estimator = "ML")

fe_semd <- '
# Define individual effects variable 
a =~ y1 + y2 + y3 + y4 + y5
# Regressions, constrain coefficient to be equal over time
y1 ~ b1*x1
y2 ~ b2*x2 
y3 ~ b3*x3
y4 ~ b4*x4
y5 ~ b5*x5
# Allow unrestricted correlation between eta and covariates
a ~~ x1 + x2 + x3 + x4 + x5
x1 ~~ x2 + x3 + x4 + x5
x2 ~~ x3 + x4 + x5
x3 ~~ x4 + x5
x4 ~~ x5
# Constrain residual variances to be equal over time
y1 ~~ e1*y1
y2 ~~ e2*y2
y3 ~~ e3*y3
y4 ~~ e4*y4
y5 ~~ e5*y5
'
fe_semd.fit <- sem( model = fe_semd, 
                   data = dfw, 
                   estimator = "ML")
```

\small
```{r}
anova( fe_sem.fit, fe_semb.fit, fe_semc.fit, fe_semd.fit)
```
\normalsize

Keep in mind that a less parsimonious model (fewer degrees of freedom) can never fit worse than a more parsimonious one (more degrees of freedom). I.e., chance variations due to sampling error mean that adding constraints to a model will tend to always worsen fit, at least minimally. The question here is whether the improvement to fit by loosening constraints is meaningful or not. In the table above, we should not expect any meaningful improvements moving from `fe_sem.fit` to `fe_semd.fit`. Here, using simulated data, we have the luxury of knowing that any significant differences in $\chi^{2}$ are due to chance. With real data, it is up to the researcher to apply their best judgment and decide whether the results are plausible or not. 

## Measurement error {#measerr}

What if the observed variables are not measured perfectly? Then what we observe, call them $\tilde{x}_{t}$ and $\tilde{y}_{t}$ are composites of the true score we are after, i.e., $x_{t}$ and $y_{t}$, plus an additive measurement error portion:
\begin{align}
\tilde{x}_{t} & = x_{t} + \upsilon_{t}, \\
\tilde{y}_{t} & = y_{t} + \nu_{t}.
\end{align}
How does this affect our model? Well, first notice that measurement error in the dependent variable is typically less of a serious problem than measurement error in the independent variables. Let us assume again mean-centered variables so that we can ignore the intercept, and consider the following simple bivariate equation:
\begin{align}
y & = \beta x + \varepsilon
\end{align}
if $y$ is measured imperfectly and what we observe is $\tilde{y} = y + \nu$, then we can rewrite the equation as: 
\begin{align}
(\tilde{y} - \nu) & = \beta x + \varepsilon \\
\tilde{y} & = \beta x + \varepsilon + \nu.
\end{align}
The measurement error in $y$ just gets added to the regression error. As long as $\nu$ is uncorrelated with $x$, then the regression coefficient will be unbiased [@Pischke2007; @Wooldridge2009]. However, this will increase the error variance and thus make the estimates less precise. 

We will look at the effect of measurement error in the dependent variable using an example shortly. For now though, let us be safe in the knowledge that the coefficient of interest is likely unbiased, and concentrate on the more serious problem of error in the independent variable. 

The intuition behind the problem of measurement error in the independent variable(s) can be explained as follows. Take $\tilde{x} = x + \upsilon$ and substitute this into the equation for $y$: 
\begin{align}
y & = \beta x + \varepsilon \\
 & = \beta(\tilde{x} - \upsilon) + \varepsilon \\
 & = \beta\tilde{x} + (\varepsilon - \beta\upsilon).
\end{align}
Since $\tilde{x}$ is obviously correlated with $\upsilon$ (unless the variance of $\upsilon$ is so small so that the correlation is essentially negligible), then the composite error in this regression is also correlated with the independent variable and thus the estimated coefficient of $\beta$ will be biased. 

### The consequences of measurement error 

To demonstrate the effect of measurement error on the FE-SEM model, and then provide a strategy for dealing with measurement error in SEM, the [simulated dataset](https://github.com/henrik-andersen/FE-SEM/blob/master/simulation-code.R) generates multiple *indicators* of the independent and dependent variables that all measure the intended variable imprecisely. Returning to our panel data, we have three indicators of each the independent and dependent variable, per timepoint:  
\begin{align}
\tilde{x}_{kt} & = x_{t} + \upsilon_{kt}, \\
\tilde{y}_{kt} & = y_{t} + \nu_{kt}
\end{align}
where $k = 1, 2, 3$ and $t = 1, ..., T$. This is like repeatedly presenting a respondent with a multi-item scale designed to measure things like stress, depression, xenophobia, etc. over the course of a panel study. To create the observed indicators, a random amount of measurement error (ranging from $\{\sigma^{2}_{\upsilon_{k}}, \sigma^{2}_{\nu_{k}}\}\in \{1.0, 1.1, 1.2, 1.3, 1.4, 1.5\}$) was added to the true variables, again see [the simulation code](https://github.com/henrik-andersen/FE-SEM/blob/master/simulation-code.R). 

Let us first focus on the issue of imprecise measurements of the independent variable of interest and run the same FE-SEM model above, but this time we will use one of the measurement error sullied indicators, here $\tilde{x}_{1t}$, instead of the true independent variable, $x_{t}$. As for the naming conventions in the `R` code, `x11` stands for the first indicator ($k = 1$) at the first point in time ($t = 1$), whereas for example `x35` stands for the third indicator ($k = 3$) at the fifth point in time ($t = 5$). 

```{r}
fe_sem2 <- '
# Define individual effects variable 
a =~ 1*y1 + 1*y2 + 1*y3 + 1*y4 + 1*y5
# Regressions, constrain coefficient to be equal over time
# Now the imprecisely measured indicator tilde{x}_kt
# instead of the true variable x_t
y1 ~ b*x11 
y2 ~ b*x12 
y3 ~ b*x13
y4 ~ b*x14
y5 ~ b*x15
# Allow unrestricted correlation between eta and covariates
a ~~ x11 + x12 + x13 + x14 + x15
x11 ~~ x12 + x13 + x14 + x15
x12 ~~ x13 + x14 + x15
x13 ~~ x14 + x15
x14 ~~ x15
# Constrain residual variances to be equal over time
y1 ~~ e*y1
y2 ~~ e*y2
y3 ~~ e*y3
y4 ~~ e*y4
y5 ~~ e*y5
'
fe_sem2.fit <- sem( model = fe_sem2, 
                    data = dfw, 
                    estimator = "ML")
```

Now, for the sake of brevity, let us look just at the estimated coefficients for $\beta$. 

```{r, echo=TRUE, output.lines=32:43}
summary( fe_sem2.fit)
```

Obviously, the estimated coefficient $\hat{\beta} =$ `r round( lavInspect( fe_sem2.fit, "list")[ 6, 14], 3)` is substantially smaller than the true population coefficient of $\beta = 0.3$. And the discrepancy is not just due to sampling error. In fact, we can derive the bias we are observing here. 

For a simple bivariate regression model, it is straightforward to quantify the bias due to measurement error. It will be 
\begin{align}
\Cov(y, \tilde{x}) & = \E[y \tilde{x}] \\
 & = \E[(\beta\tilde{x} + \varepsilon)\tilde{x}] \\
 & = \E[\beta\tilde{x}^{2} + \varepsilon \tilde{x}] \\
 & = \beta \Var(\tilde{x}) \\
\hat{\beta} & = \frac{\Cov(y, \tilde{x})}{\Var(\tilde{x})} \\
 & = \frac{\E[(\beta x + \varepsilon)(x + \upsilon)]}{\E[(x + \upsilon)^{2}]} \\
 & = \frac{\E[\beta x^{2} + \beta x \upsilon + \varepsilon x + \varepsilon \upsilon]}{\E[x^{2} + 2 x \upsilon + \upsilon^{2}]} \\
 & = \beta \frac{\Var(x)}{\Var(x) + \Var(\upsilon)}.
\end{align}
which results if we assume that $\E[x \upsilon] = 0$, $\E[x \varepsilon] = 0$, $\E[\tilde{x} \varepsilon] = 0$ and $\E[\varepsilon \upsilon] = 0$ [@Wooldridge2009]. However, the model we are interested is not a bivariate model, so what was the point of showing the this? For one, it points out that the bias will always move the estimated coefficient closer to 0, since $\Var(x) \le \Var(x) + \Var(\upsilon)$. This means positive effects will be biased downwards and negative effects biased upwards, always towards zero. This is why it is referred to as *attenuation bias*. Second, it will help to familiarize ourselves with this equation to better understand the one for the multivariate case. 

Indeed, the magnitude of the bias in a multivariate model is somewhat more complex to derive, but it will be 
\begin{align}
\hat{\beta} & = \beta \frac{\Var(\theta)}{\Var(\theta) + \Var(\upsilon)}
\end{align}
where $\theta$ is just the residual of a regression in which the underlying theoretical variable is regressed on all other covariates. In this case, we need to regress $x_{t}$ on $\alpha_{1}$ and $\alpha_{2}$ for: $x_{t} = \tau + \gamma_{1}\alpha_{1} + \gamma_{2}\alpha_{2} + \theta_{t}$ where $\tau$ is the intercept, and $\gamma_{1}$, $\gamma_{2}$ are the regression coefficients and $\theta_{t}$ is the residual [@Wooldridge2009, p. 318--320].

Normally it is not possible to reconstruct the bias since in cases where we have to rely on indicators, we would not have observed the underlying theoretical variable. Furthermore, in the case of a fixed-effects model, the covariates are the unobserved time-invariant characteristics. However, because we are working with simulated data, we have everything we need. Going back to the results above, we can get the residuals of $x_{t}$ by either running a regression and saving the residuals, or we could skip a step and get them directly using the 'residual maker' matrix [@Ruettenauer2020] which is $\bm{M} = \bm{I} - \bm{A}(\bm{A}^{\intercal}\bm{A})^{-1}\bm{A}^{\intercal}$ and $\bm{A} = \begin{pmatrix}\bm{\iota}_{n} & \bm{\alpha_{1}} & \bm{\alpha_{2}}\end{pmatrix}$ is the $n \times 3$ matrix of the covariates (plus a constant).

```{r}
# Make the n x n identity matrix
Id <- diag( n)

# n x 2 matrix of covariates a1 and a2
A <- matrix( c( rep( 1, n), dfw$a1, dfw$a2), 
             nrow = n, ncol = 3)

# The residual maker matrix M = I - A(A'A)^-1 A'
M <- Id - A %*% solve( t( A) %*% A) %*% t( A)

# Save the residuals, t for 'theta'
t <- M %*% dfw$x1

# Re-run the FE model from above with the 'true' 
# independent variable for the correct estimate for beta 
fe_sem.fit <- sem( model = fe_sem, data = dfw, estimator = "ML")

# The equation for the biased beta 
lavInspect( fe_sem.fit, "list")[ 6, 14]*
  (( var( t))/( var( t) + var( dfw$x11 - dfw$x1)))
```

```{r, echo=FALSE, results=FALSE}
b <- lavInspect( fe_sem.fit, "list")[ 6, 14]
vart <- var( t)
varu <- var( dfw$x11 - dfw$x1)
```

From this we can see that the biased estimate above of $\hat{\beta} =$ `r round( lavInspect( fe_sem2.fit, "list")[ 6, 14], 3)` roughly comes from $\beta \frac{\Var(\theta_{t})}{\Var(\theta_{t}) + \Var(\upsilon_{t})} = `r round( b, 3)` \frac{`r  round( vart, 3)`}{`r  round( vart + varu, 3)`}$ = `r round( b*(( vart)/( vart + varu)), 3)`; 'roughly' because the equation here is the population equation. Due to sampling error, the estimates will tend vary slightly.  

### Using latent variables to deal with measurement error 

The way we deal with measurement error in SEM is surprisingly similar to the logic of fixed-effects regression. Namely, if we have multiple cross-sectional observations of the underlying construct of interest, then we can define a latent variable that represents the common variance across those multiple variables. Contrast this with the use of longitudinal repeated measures to isolate the common variance across time. 

So, if we do in fact have multiple cross-sectional indicators for the underlying variables of interest, then we can partition them into an explained and unexplained portion:  
\begin{align}
x_{kt} & = \lambda_{kt}^{x}\xi_{t} + \delta_{kt}, \\
y_{kt} & = \lambda_{kt}^{y}\eta_{t} + \varepsilon_{kt},
\end{align}
where $x_{kt}$ and $y_{kt}$ are the $k^{th}$ indicators, $\xi_{t}$ and $\eta_{t}$ are latent factors representing the common variance across the cross-sectional repeated measures, and $\delta_{kt}$ and $\varepsilon_{kt}$ are the unexplained portions of $x_{t}$ and $y_{t}$, respectively. The latent factors are linked to the observed indicators through the factor loadings $\lambda_{kt}$. 

Thus, our FE regression equation changes from $y_{t} = \beta x_{t} + \alpha + \varepsilon_{t}$ to:
\begin{align}
\eta_{t} & = \beta \xi_{t} + \alpha + \zeta_{t}
\end{align}
where $\zeta_{t}$ represents the disturbance, in other words the residual of the latent dependent variable $\eta_{t}$. 
First, however, let us double-check that measurement error in the dependent variable only increases the error variance (thus also increasing standard errors and reducing $R^{2}$), but does not systematically bias the coefficients of interest. The next model uses the indicators of $x$ and specifies latent variables ($\xi_{t}$, `xi` in the code) to represent the valid cross-sectional variance. The dependent variable in the model is one of the impercisely measured indicators of $y$.   

```{r}
fe_sem3 <- '
# Define individual effects variable 
a =~ 1*y11 + 1*y12 + 1*y13 + 1*y14 + 1*y15
# Measurement model for independent variables, xi 
xi1 =~ 1*x11 + x21 + x31 
xi2 =~ 1*x12 + x22 + x32
xi3 =~ 1*x13 + x23 + x33
xi4 =~ 1*x14 + x24 + x34
xi5 =~ 1*x15 + x25 + x35
# Regressions, constrain coefficient to be equal over time
y11 ~ b*xi1
y12 ~ b*xi2 
y13 ~ b*xi3
y14 ~ b*xi4
y15 ~ b*xi5
# Allow unrestricted correlation between eta and covariates
a ~~ xi1 + xi2 + xi3 + xi4 + xi5
xi1 ~~ xi2 + xi3 + xi4 + xi5
xi2 ~~ xi3 + xi4 + xi5
xi3 ~~ xi4 + xi5
xi4 ~~ xi5
# Constrain residual variances to be equal over time
y11 ~~ e*y11
y12 ~~ e*y12
y13 ~~ e*y13
y14 ~~ e*y14
y15 ~~ e*y15
'
fe_sem3.fit <- sem( model = fe_sem3, 
                    data = dfw, 
                    estimator = "ML")
```

```{r, output.lines=51:62}
summary( fe_sem3.fit)
```

The estimated coefficient here in model `fe_sem3.fit` is $\hat{\beta}_{y_{1t},\xi_{t}} =$ `r round( lavInspect( fe_sem3.fit, "list")[ 21, 14], 3)` which is very close to the estimated coefficient in the first, correctly specified model `fe_sem.fit`, where $\hat{\beta}_{y_{t},x_{t}} =$ `r round( lavInspect( fe_sem.fit, "list")[ 6, 14], 3)`. Notice, however, that the standard error of the estimate is substantially larger, with `r round( lavInspect( fe_sem3.fit, "list")[ 21, 15], 3)` in `fe_sem3.fit` vs. `r round( lavInspect( fe_sem.fit, "list")[ 6, 15], 3)` in `fe_sem.fit` in which $y$ was measured without error. The explained variance ($R^{2}$) in the dependent variable was also much higher in the first model: 

```{r}
lavInspect( fe_sem.fit, "r2")[ 1:5]
```

compared to the current model: 

```{r}
lavInspect( fe_sem3.fit, "r2")[ 1:5]
```

Finally, to see the benefits of removing measurement error from the dependent variable in terms of standard errors and $R^{2}$ statistics, we can specify a model with latent variables representing the valid cross-sectional variance in $y$ (`n` for $\eta$ in the code). 

```{r}
fe_sem4 <- '
# Measurement model for dependent variable, n for eta
n1 =~ 1*y11 + y21 + y31
n2 =~ 1*y12 + y22 + y32
n3 =~ 1*y13 + y23 + y33
n4 =~ 1*y14 + y24 + y34
n5 =~ 1*y15 + y25 + y35
# Define individual effects variable 
a =~ 1*n1 + 1*n2 + 1*n3 + 1*n4 + 1*n5
# Measurement model for independent variables, xi 
xi1 =~ 1*x11 + x21 + x31 
xi2 =~ 1*x12 + x22 + x32
xi3 =~ 1*x13 + x23 + x33
xi4 =~ 1*x14 + x24 + x34
xi5 =~ 1*x15 + x25 + x35
# Regressions, constrain coefficient to be equal over time
n1 ~ b*xi1
n2 ~ b*xi2 
n3 ~ b*xi3
n4 ~ b*xi4
n5 ~ b*xi5
# Allow unrestricted correlation between eta and covariates
a ~~ xi1 + xi2 + xi3 + xi4 + xi5
xi1 ~~ xi2 + xi3 + xi4 + xi5
xi2 ~~ xi3 + xi4 + xi5
xi3 ~~ xi4 + xi5
xi4 ~~ xi5
# Constrain residual variances to be equal over time
n1 ~~ e*n1
n2 ~~ e*n2
n3 ~~ e*n3
n4 ~~ e*n4
n5 ~~ e*n5
'
fe_sem4.fit <- sem( model = fe_sem4, 
                    data = dfw, 
                    estimator = "ML")
```

```{r, output.lines=71:82}
summary( fe_sem4.fit)
```

Here, the effect $\hat{\beta}_{\eta_{t},\xi_{t}}$ is somewhat further off of the true effect of 0.3 than the preceding models. This will depend on how the latent variables are estimated, which themselves will depend on the underlying correlations between the indicators. Again, if the main goal of the model is to avoid bias, it may be advisable to just leave the manifest dependent variable as it is, and worry about measurement error in the independent variables. 

## Time-invariant predictors

What if we do not just want to just control for the effects of all time-invariant variables, but investigate some of them in detail? Many time-invariant variables, like sex, birth cohort, nationality, education, etc. can be interesting on their own. And typically, many of these variables are readily available in a given dataset. The traditional OLS-based FE model does not allow for this, as it wipes out the effect of *all* time-invariant variables, whether observed or not. 

In SEM, we can easily specify a type of *hybrid* FE/RE model [@Bollen2010] that allows us to control for time-invariant unobserved heterogeneity while also investigating the effects of specific observed time-invariant predictors.^[These types of models have become well known outside of SEM as well, see for example @Allison2011; @Schunck2013; @Bell2018.]

In the next example, we continue with the most complex model we have specified so far, `fe_sem4.fit` in which measurement error in both the independent and dependent variables is accounted for using latent variables. Now, we would like as well to specifically investigate the effect of $\alpha_{2}$ on the dependent variable. The equation for this model changes to: $\eta_{t} = \beta \xi_{t} + \alpha + \gamma \alpha_{2} + \zeta_{t}$. 

```{r eval=TRUE}
fe_sem5 <- '
# Measurement model for dependent variable, n for eta
n1 =~ 1*y11 + y21 + y31
n2 =~ 1*y12 + y22 + y32
n3 =~ 1*y13 + y23 + y33
n4 =~ 1*y14 + y24 + y34
n5 =~ 1*y15 + y25 + y35
# Define individual effects variable 
a =~ 1*n1 + 1*n2 + 1*n3 + 1*n4 + 1*n5
# Measurement model for independent variables, xi 
xi1 =~ 1*x11 + x21 + x31 
xi2 =~ 1*x12 + x22 + x32
xi3 =~ 1*x13 + x23 + x33
xi4 =~ 1*x14 + x24 + x34
xi5 =~ 1*x15 + x25 + x35
# Regressions, constrain coefficient to be equal over time
n1 ~ b*xi1 + g*a2
n2 ~ b*xi2 + g*a2
n3 ~ b*xi3 + g*a2
n4 ~ b*xi4 + g*a2
n5 ~ b*xi5 + g*a2
# Allow unrestricted correlation between eta and covariates
a ~~ xi1 + xi2 + xi3 + xi4 + xi5 + 0*a2
a2 ~~ xi1 + xi2 + xi3 + xi4 + xi5
xi1 ~~ xi2 + xi3 + xi4 + xi5
xi2 ~~ xi3 + xi4 + xi5
xi3 ~~ xi4 + xi5
xi4 ~~ xi5
# Constrain residual variances to be equal over time
n1 ~~ e*n1
n2 ~~ e*n2
n3 ~~ e*n3
n4 ~~ e*n4
n5 ~~ e*n5
'
fe_sem5.fit <- sem( model = fe_sem5, 
                    data = dfw, 
                    estimator = "ML")
```

Keep in mind, based on the DGP, the true parameters are $\beta = 0.3$ and $\gamma = 0.45$.

```{r, output.lines=71:87, eval=TRUE}
summary( fe_sem5.fit)
```

From this we can see that such a hybrid model is does a good job of estimating the coefficients of interest, with $\hat{\beta} =$ `r round( lavInspect( fe_sem5.fit, "list")[ 36, 14], 3)` (`r round( lavInspect( fe_sem5.fit, "list")[ 36, 15], 3)`) and $\hat{\gamma} =$ `r round( lavInspect( fe_sem5.fit, "list")[ 37, 14], 3)` (`r round( lavInspect( fe_sem5.fit, "list")[ 37, 15], 3)`). 

It is important, however, to realize that the unbiasedness of $\hat{\gamma}$ in this model is dependent on the assumption that $\E[\zeta | \bm{\xi_{t}}, \alpha_{2}] = 0$. In other words, the idiosyncratic error is mean independent of $\bm{\xi_{t}} = (\xi_{1}, \xi_{2}, ..., \xi_{T})$ as well as $\alpha_{2}$. The first part is easier to accept because we are controlling for all potential time-invariant confounders that could induce a relationship between the independent variable and the error. The unbiasedness of $\hat{\gamma}$, on the other hand rests on the assumption that the time-invariant predictor is independent of the error. If $\alpha_{2}$ represented the respondent's intelligence and $\eta_{t}$, the dependent variable, represented the respondent's income, for example, then $\hat{\gamma}$ would be biased if both were dependent on a third time-invariant variable, say level of schooling, if it is not controlled for. For this reason, we need to treat the regression on a time-invariant predictor like any other regular multivariate regression model and look to include all plausible potential confounders as controls in the model, or turn to other methods, e.g., instrumental variables. 

# References 